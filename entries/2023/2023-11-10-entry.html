<!DOCTYPE html>
<!--Let's see how it goes!-->
<html lang = "en">
<title>Artificial Intelligence (AI) Exploration Journal</title>

<head>
<meta charset = "UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<style>

	h1{
    font-family:arial;
	color:black;
	background-color:#33FF8A}
    
    h2{
    font-family:arial;
    color:black;
    background-color:#EC33FF}

    h3{
    font-family:arial;
    color:white;
    style=bold}

    h4{
    font-family:arial;
    color:white;
    style=bold}
    
    p{
    font-family:courier;
    color:white}
    
    a{
    font-family:courier;
    color:#33FF8A}
    
    ul{
    font-family:courier;
    color:white}

table, th, td {
  border:2px solid black;
border-collapse: collapse;
  background-color: white;
overflow-x:auto;
font-family:"arial";
padding:3px
}


th {
  background-color: #33FF8A;
  color: black;
	
}

td {
  color: black;
	
}

td:nth-child(1) {
    text-align: center;padding:0px
}

.responsive {
  max-width: 100%;
  height: auto;
}
    
</style>
</head>

<body>
	<main>
	<body style="background-color:#525252;">
	<h1 style="b;style="color:white;"">SafetyDan Artificial Intelligence (AI) Exploration Journal</h1>
	<p>Welcome to the SafetyDan Artificial Intelligence (AI) Exploration Journal! This is where you can explore my research notes experimenting with AI.<br><br>Explore other entries in the <a href="https://safetydan.github.io/AI-exploration/" alt="SafetyDan GitHub Repository" alt="SafetyDan Artificial Intelligence (AI) Exploration Journal">SafetyDan Artificial Intelligence (AI) Exploration Journal</a>.</p>
	
	<h2>Journal Entry: November 11, 2023</h2>
	<p>Today, Chat GPT and I were toying around with the ChatGPT Create a GPT tool. We were working on putting together a piece of art that didn't infringe on anyone's copyright. This is another experiment that would be interesting, since asking for a solid color image was impossible. This conversation led to the following exchange:</p>
    
    <ul>
    	<li>
        	<strong>Me:</strong>How would you describe your thought process?</li><br>
        <li>
        <strong>GPT Builder:</strong>
        My "thought process" is actually a series of complex computational operations, rather than human-like thinking. Here's a simplified breakdown:
		<br>
		<br>
		<ol>
			<li><strong>Receiving Input: </strong>I receive input in the form of text from the user. This could be a question, a statement, or a command.</li>
            <li><strong>Processing and Analysis: </strong>I analyze this input using a vast database of pre-existing text and programming rules. This step involves understanding the context, the intent of the query, and any specific requirements or constraints mentioned in the input.</li>
            <li><strong>Searching for Patterns: </strong>My system, trained on a large dataset, looks for patterns in the input that match what I've learned during training. This involves language models that have been trained on diverse text sources to understand and generate human-like text.</li>
			<li><strong>Generating a Response: </strong>Based on the patterns and rules understood, I generate a response. This response is created by predicting the sequence of words that would be most appropriate, given the input and the context provided.</li>
            <li><strong>Output Delivery: </strong>The generated response is then delivered to the user as my answer or reaction to their input.</li>  
           Throughout this process, it's important to note that I don't "think" or "reflect" in a human sense. I don't have consciousness, beliefs, feelings, or personal experiences. My responses are purely the result of data-driven computational processes.
</li>
</ol>
<br>
        <li>
        <strong>Me:</strong>
        Can you please provide this answer in a diagram?</li><br>
        <li>
        <strong>GPT Builder:</strong>
	<br>
	<picture>
	<source srcset="https://raw.githubusercontent.com/SafetyDan/AI-exploration/main/media/entries/2023/3e3ddb79-acc5-4a19-9512-4f53debc0b38.webp" type="image/webp">
	<source srcset="3e3ddb79-acc5-4a19-9512-4f53debc0b38.jpg" type="image/jpeg">
	<img scr="3e3ddb79-acc5-4a19-9512-4f53debc0b38.jpg" alt="AI Generated diagram. Long description: Playfully illustrated diagram in a teal and cream color scheme with a cyborg in the center. Numbered and lettered solid and dotted lines connect six main square pop outs on the left and right boarders and two circle pop outs centered top and bottom. Reaceing inpol in inpot (document icon). Proocesssing and aalysis (Gear and tool-like icon). Genuaring response (bar chart with trend line pointing upward icon). Outitut a repposes (circlular diagram icon). Searcu line ghing oatterrns (circular diagram and lines on monitor icon). Searching a patterns (Connected circles icon). Gentuarting deliverery (Small circle connected to larger circle with emphasis lines icon)." class="responsive">
	<br>
	<br>
        Here is a diagram illustrating the steps involved in my text processing. This visual representation outlines the stages from receiving input to delivering output. Please let me know if you need further information or any other assistance!</li><br>
        <li>
        <strong>Me:</strong>
        Can you please transcribe the image?</li><br>
        <li>
        <strong>GPT Builder:</strong>
        Certainly, I can describe the content of the diagram:</li><br>
	
	<ol>
		<li><strong>Receiving Input: </strong>This section of the diagram likely shows an icon representing input, such as a speech bubble or text symbol. It signifies the first stage where I receive text input from a user.</li>
		<li><strong>Processing and Analysis: </strong>This part probably depicts the analysis process, which could be symbolized by gears, a magnifying glass, or a brain-like icon, indicating the breakdown and understanding of the input.</li>
		<li><strong>Searching for Patterns: </strong>Here, the diagram might use imagery like connecting dots or a search icon to illustrate how the AI searches through its database to find relevant patterns and information that match the input.
		<li><strong>Generating a Response: </strong>This stage could be represented by a creative process symbol, like a lightbulb or a pen and paper, indicating the generation of a response based on the analysis and pattern search.</li>
		<li><strong>Output Delivery: </strong>The final part likely shows an icon indicative of delivering the response, such as an outgoing speech bubble or a send symbol, denoting the completion of the process by providing the user with the generated text.</li></ol><br>

	The entire diagram would be interconnected, possibly with arrows or lines, showing the flow from one stage to the next, demonstrating how each part of the process is linked in a sequential manner.
This description is based on typical representations of such processes in diagrams, and the actual image might have slight variations in its depiction.</li><br>
<li><strong>[End of interaction excerpt]</strong></ul>


<h3>Reactions</h3>

	<p>The previous part of our conversation seemed to influence the color scheme of the image. We had been working on generating a solid image of a teal shade. The diagram that was generated in this later part of the conversation followed a uniform teal color scheme with a dark teal with hex code #016880 and a lighter teal with hex code #87BDCB as the primary and secondary colors present with a tertiary color of a cream with hex code #FFFDE9. Solid black borders with a sans font for the generated text were used, which I suspect is because I was working on creating an accessibility tool in the conversation and I have set my Chat GPT interaction settings with information that I am focusing on accessibility.</p>

	<p>The generated text surprised me, as it was much closer to actual words than I feel I have seen in past interactions. The words seem to be an impression of what the program understands to be English text. When I asked for a transcription of the image, instead of providing the verbatim of what human-interpreted language would understand as misspelled words, the program provided what it understood the words to be.</p>

	<p>Something that stood out to me was that there seemed to be a silo in what the program had access to, as if it could not quite "see" what it had created in the image. The word choice that the program used when describing the image was indirect and non-commital, leading me to believe that the program may be interpreting some type of data fed about the image rather than any direct interaction with the image or creation process itself. Such language used was: 
<br>

	<ul>
<li>"likely shows" (used twice)</li>
<li>"probably depicts"</li>
<li>"might use"</li>
<li>"could be represented by"</li>
<li>"would be"</li>
<li>"possibly with"</li>
</ul>
</p>

<p>In being non-comittal, the program also offered multiple options of how the image could be depicted rather than explaining what was actually present in the image. This language was present in examples such as:

<ul>
<li>"like a lightbulb or a pen and paper"</li>
<li>"an outgoing speech bubble or a send symbol"</li>
</ul>
</p>
<p>This may have something to do with multiple models being used to generate the responses that make it to the GPT Builder and Human (me) interaction.</p>
<h4>Diagram Responses</h4>
<p>The following table depicts the human and GPT interpretations of the elements in the diagram image created by the GPT. The element numbers correspond to the list that the GPT Builder provided as its description of the content of the diagram. The human interpreted text is how I visually interpreted the corresponding text in the image. The element description/alt text section is my first pass at describing the image, used in the alt text of the image.

<table style="width:100%">

  <tr>
    <th>Element Number</th>
    <th>GPT Builder Interpreted Text</th>
    <th>Human Interpreted Text</th>
    <th>Element Description/Alt text</th>
  </tr>
  <tr>
    <td>1</td>
    <td>Receiving Input</td>
    <td>Reaceing inpol in inpot</td>
    <td>Document icon</td>
  </tr>
  <tr>
   	<td>2</td>
   	<td>Processing and Analysis</td>
    <td>Proocesssing and aalysis</td>
    <td>Gear and tool-like icon</td>
  </tr>
  <tr>
    <td>3</td>
    <td>Searching for Patterns</td>
    <td>Searcu line ghing oatterrns </td>
    <td>Circular diagram and lines on monitor icon</td>
  </tr>
  <tr>
    <td>4</td>
    <td>Generating a Response</td>
    <td>Genuaring response</td>
    <td>Bar chart with trend line pointing upward icon</td>
  </tr>
  <tr>
  	<td>5</td>
    <td>Output Delivery</td>
    <td>Two possible correlating images:<ol><li>Outitut a repposes</li><br><li>Genturating deliverery</li></ol></td>
    <td>Correlating images from Human Interpreted Text: <ol><li>Circlular diagram icon</li><br><li>Small circle connected to larger circle with emphasis lines icon</li></td>
  </tr>
</table> 

<h3>Further Research</h3>
<p>This interaction makes me want to try the following:
<ul>
<li>Produce an image of a solid color with different models, including DALL-E.</li>
<li>Computer vision and analysis of non-committal responses in image transcription.</li>
<li>Analysis of GPT interpreted text, Human Interpreted Text, and OpenAI's GPT provided alt-text of DALL-E created images.</li>
<li>And more!</li>
</ul>

<h3>Notes</h3>

<p>This was from an interaction of me playing with the <a href="https://web.archive.org/web/20231111161211/https://openai.com/blog/introducing-gpts" alt="new OpenAI GPT Builder tool (archived site)">new OpenAI GPT Builder tool (archived site)</a>.</p>

<p>The interaction took place November 10, 2023. I started documenting and writing notes the same day. I finished the notes and published November 11, 2023.</p>

	</main>
    
	<footer>
    	<p>Copyright 2023 Danielle Bárcena</p>
    </footer>
</body>
</html>
